{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.cpp_extension\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.randn(4, 8, 32, 32768, device='cuda', dtype=torch.float32)\n",
    "small = torch.tensor([[1, 2, 3]], device='cuda', dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128 μs ± 108 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.nn.functional.softmax(matrix, dim=-1)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_pytorch_softmax(x, dim=None):\n",
    "    m = torch.max(x, dim=dim, keepdim=True)[0]\n",
    "    e = torch.exp(x - m)\n",
    "    s = torch.sum(e, dim=dim, keepdim=True)\n",
    "    return e / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(naive_pytorch_softmax(matrix, dim=-1), torch.nn.functional.softmax(matrix, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371 μs ± 321 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "naive_pytorch_softmax(matrix, dim=-1)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_begin = r'''\n",
    "#include <torch/extension.h>\n",
    "#include <stdio.h>\n",
    "#include <c10/cuda/CUDAException.h>\n",
    "\n",
    "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
    "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
    "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
    "\n",
    "inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a + b - 1) / b;}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/belevich/.cache/torch_extensions/py312_cu126 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/belevich/.cache/torch_extensions/py312_cu126/my1/build.ninja...\n",
      "/fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module my1...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module my1...\n"
     ]
    }
   ],
   "source": [
    "softmax1_cu = Path('softmax1.cu').read_text()\n",
    "cuda_src1 = cuda_begin + \"\\n\" + softmax1_cu\n",
    "cpp_src1 = \"\"\"\n",
    "torch::Tensor softmax1(const torch::Tensor& x);\n",
    "\"\"\"\n",
    "my1 = torch.utils.cpp_extension.load_inline(\n",
    "    \"my1\", cpp_src1, cuda_src1,\n",
    "    functions=['softmax1'], extra_cuda_cflags=['--ptxas-options=-v'], verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(my1.softmax1(matrix), torch.nn.functional.softmax(matrix, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.5 ms ± 92.9 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "my1.softmax1(matrix)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/belevich/.cache/torch_extensions/py312_cu126 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/belevich/.cache/torch_extensions/py312_cu126/my2/build.ninja...\n",
      "/fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module my2...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module my2...\n"
     ]
    }
   ],
   "source": [
    "softmax2_cu = Path('softmax2.cu').read_text()\n",
    "cuda_src2 = cuda_begin + \"\\n\" + softmax2_cu\n",
    "cpp_src2 = \"\"\"\n",
    "torch::Tensor softmax2(const torch::Tensor& x);\n",
    "\"\"\"\n",
    "my2 = torch.utils.cpp_extension.load_inline(\n",
    "    \"my2\", cpp_src2, cuda_src2,\n",
    "    functions=['softmax2'], extra_cuda_cflags=['--ptxas-options=-v'], verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(my2.softmax2(matrix), torch.nn.functional.softmax(matrix, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 μs ± 67.8 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "my2.softmax2(matrix)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/belevich/.cache/torch_extensions/py312_cu126 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/belevich/.cache/torch_extensions/py312_cu126/my3/build.ninja...\n",
      "/fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module my3...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module my3...\n"
     ]
    }
   ],
   "source": [
    "softmax3_cu = Path('softmax3.cu').read_text()\n",
    "cuda_src3 = cuda_begin + \"\\n\" + softmax3_cu\n",
    "cpp_src3 = \"\"\"\n",
    "torch::Tensor softmax3(const torch::Tensor& x);\n",
    "\"\"\"\n",
    "my3 = torch.utils.cpp_extension.load_inline(\n",
    "    \"my3\", cpp_src3, cuda_src3,\n",
    "    functions=['softmax3'], extra_cuda_cflags=['--ptxas-options=-v'], verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(my3.softmax3(matrix), torch.nn.functional.softmax(matrix, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 μs ± 20.1 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "my3.softmax3(matrix)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/belevich/.cache/torch_extensions/py312_cu126 as PyTorch extensions root...\n",
      "The input conditions for extension module my2_shfl have changed. Bumping to version 6 and re-building as my2_shfl_v6...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/belevich/.cache/torch_extensions/py312_cu126/my2_shfl/build.ninja...\n",
      "/fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module my2_shfl_v6...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=my2_shfl_v6 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/include -isystem /fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda/include -isystem /fsxl/belevich/miniconda3/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -c /home/belevich/.cache/torch_extensions/py312_cu126/my2_shfl/main.cpp -o main.o \n",
      "[2/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=my2_shfl_v6 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/include -isystem /fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda/include -isystem /fsxl/belevich/miniconda3/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --ptxas-options=-v -std=c++17 -c /home/belevich/.cache/torch_extensions/py312_cu126/my2_shfl/cuda.cu -o cuda.cuda.o \n",
      "ptxas info    : 11 bytes gmem\n",
      "ptxas info    : Compiling entry function '_Z20softmax2_shfl_kernelPKfPfii' for 'sm_90'\n",
      "ptxas info    : Function properties for _Z20softmax2_shfl_kernelPKfPfii\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 26 registers, used 1 barriers\n",
      "ptxas info    : Compile time = 24.441 ms\n",
      "[3/3] c++ main.o cuda.cuda.o -shared -L/fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o my2_shfl_v6.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module my2_shfl_v6...\n"
     ]
    }
   ],
   "source": [
    "softmax2_shfl_cu = Path('softmax2_shfl.cu').read_text()\n",
    "cuda_src2_shfl = cuda_begin + \"\\n\" + softmax2_shfl_cu\n",
    "cpp_src2_shfl = \"\"\"\n",
    "torch::Tensor softmax2_shfl(const torch::Tensor& x);\n",
    "\"\"\"\n",
    "my2_shfl = torch.utils.cpp_extension.load_inline(\n",
    "    \"my2_shfl\", cpp_src2_shfl, cuda_src2_shfl,\n",
    "    functions=['softmax2_shfl'], extra_cuda_cflags=['--ptxas-options=-v'], verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(my2_shfl.softmax2_shfl(matrix), torch.nn.functional.softmax(matrix, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 μs ± 40.2 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "my2_shfl.softmax2_shfl(matrix)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/belevich/.cache/torch_extensions/py312_cu126 as PyTorch extensions root...\n",
      "The input conditions for extension module my3_shfl have changed. Bumping to version 2 and re-building as my3_shfl_v2...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/belevich/.cache/torch_extensions/py312_cu126/my3_shfl/build.ninja...\n",
      "/fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "Building extension module my3_shfl_v2...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=my3_shfl_v2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/include -isystem /fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda/include -isystem /fsxl/belevich/miniconda3/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++17 -c /home/belevich/.cache/torch_extensions/py312_cu126/my3_shfl/main.cpp -o main.o \n",
      "[2/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=my3_shfl_v2 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1016\\\" -isystem /fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/include -isystem /fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /usr/local/cuda/include -isystem /fsxl/belevich/miniconda3/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_90,code=compute_90 -gencode=arch=compute_90,code=sm_90 --compiler-options '-fPIC' --ptxas-options=-v -std=c++17 -c /home/belevich/.cache/torch_extensions/py312_cu126/my3_shfl/cuda.cu -o cuda.cuda.o \n",
      "ptxas info    : 11 bytes gmem\n",
      "ptxas info    : Compiling entry function '_Z20softmax3_shfl_kernelPKfPfii' for 'sm_90'\n",
      "ptxas info    : Function properties for _Z20softmax3_shfl_kernelPKfPfii\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 26 registers, used 1 barriers\n",
      "ptxas info    : Compile time = 24.415 ms\n",
      "[3/3] c++ main.o cuda.cuda.o -shared -L/fsxl/belevich/miniconda3/lib/python3.12/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o my3_shfl_v2.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module my3_shfl_v2...\n"
     ]
    }
   ],
   "source": [
    "softmax3_shfl_cu = Path('softmax3_shfl.cu').read_text()\n",
    "cuda_src3_shfl = cuda_begin + \"\\n\" + softmax3_shfl_cu\n",
    "cpp_src3_shfl = \"\"\"\n",
    "torch::Tensor softmax3_shfl(const torch::Tensor& x);\n",
    "\"\"\"\n",
    "my3_shfl = torch.utils.cpp_extension.load_inline(\n",
    "    \"my3_shfl\", cpp_src3_shfl, cuda_src3_shfl,\n",
    "    functions=['softmax3_shfl'], extra_cuda_cflags=['--ptxas-options=-v'], verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(my3_shfl.softmax3_shfl(matrix), torch.nn.functional.softmax(matrix, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 μs ± 42.7 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "my3_shfl.softmax3_shfl(matrix)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
